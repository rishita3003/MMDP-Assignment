{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Part e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# PART E: MULTIMODAL CORRELATION\n",
    "#################################################################\n",
    "\n",
    "def analyze_multimodal_correlations(text_data, audio_data, tfidf_df):\n",
    "    \"\"\"Analyze correlations between text and audio features.\"\"\"\n",
    "    print(\"\\n--- MULTIMODAL CORRELATION ANALYSIS ---\")\n",
    "    \n",
    "    # Check if both modalities are available\n",
    "    if text_data is None or audio_data is None or tfidf_df is None:\n",
    "        print(\"Missing data for multimodal analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Find common countries\n",
    "    common_countries = set(tfidf_df.index).intersection(set(audio_data.index))\n",
    "    print(f\"Found {len(common_countries)} countries with both text and audio data.\")\n",
    "    \n",
    "    if len(common_countries) < 5:\n",
    "        print(\"Not enough data for meaningful multimodal analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Filter data to include only common countries\n",
    "    common_countries = list(common_countries)\n",
    "    filtered_audio = audio_data.loc[common_countries]\n",
    "    filtered_tfidf = tfidf_df.loc[common_countries]\n",
    "    \n",
    "    # Create musical-semantic feature vectors\n",
    "    \n",
    "    # 1. Reduce dimensionality of text data\n",
    "    text_pca = PCA(n_components=5)\n",
    "    text_components = text_pca.fit_transform(filtered_tfidf)\n",
    "    \n",
    "    # 2. Reduce dimensionality of audio data\n",
    "    audio_pca = PCA(n_components=5)\n",
    "    audio_components = audio_pca.fit_transform(filtered_audio.fillna(0))\n",
    "    \n",
    "    # 3. Create combined feature vectors\n",
    "    combined_features = np.hstack((text_components, audio_components))\n",
    "    \n",
    "    # 4. Save combined features\n",
    "    combined_df = pd.DataFrame(combined_features, index=common_countries)\n",
    "    combined_df.columns = [f'text_pc{i+1}' for i in range(5)] + [f'audio_pc{i+1}' for i in range(5)]\n",
    "    combined_df.to_csv(os.path.join(RESULTS_DIR, 'combined_features.csv'))\n",
    "    \n",
    "    # 5. Calculate correlation between text and audio principal components\n",
    "    correlation_matrix = np.zeros((5, 5))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            correlation_matrix[i, j] = np.corrcoef(text_components[:, i], audio_components[:, j])[0, 1]\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm',\n",
    "                xticklabels=[f'Audio PC{i+1}' for i in range(5)],\n",
    "                yticklabels=[f'Text PC{i+1}' for i in range(5)])\n",
    "    plt.title('Correlation Between Text and Audio Principal Components')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'text_audio_correlation.png'))\n",
    "    \n",
    "    # 6. Create similarity matrices for both modalities\n",
    "    text_sim = cosine_similarity(filtered_tfidf)\n",
    "    audio_sim = cosine_similarity(filtered_audio.fillna(0))\n",
    "    \n",
    "    # 7. Calculate correlation between similarity matrices\n",
    "    # Flatten the upper triangular part of both matrices\n",
    "    indices = np.triu_indices(len(common_countries), k=1)\n",
    "    text_sim_flat = text_sim[indices]\n",
    "    audio_sim_flat = audio_sim[indices]\n",
    "    similarity_correlation = np.corrcoef(text_sim_flat, audio_sim_flat)[0, 1]\n",
    "    \n",
    "    print(f\"\\nCorrelation between text and audio similarity matrices: {similarity_correlation:.4f}\")\n",
    "    \n",
    "    # 8. Visualize combined space with t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_result = tsne.fit_transform(combined_features)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.8)\n",
    "    \n",
    "    # Add country labels\n",
    "    for i, country in enumerate(common_countries):\n",
    "        plt.annotate(country, (tsne_result[i, 0], tsne_result[i, 1]), \n",
    "                    fontsize=8, alpha=0.8)\n",
    "    \n",
    "    plt.title('t-SNE Visualization of Combined Text and Audio Features')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'combined_tsne.png'))\n",
    "    \n",
    "    # 9. Clustering on combined features\n",
    "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "    clusters = kmeans.fit_predict(combined_features)\n",
    "    \n",
    "    # Create a DataFrame with clustering results\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'Country': common_countries,\n",
    "        'Cluster': clusters\n",
    "    })\n",
    "    \n",
    "    # Print clusters\n",
    "    print(\"\\nMultimodal clusters:\")\n",
    "    for cluster_id in range(5):\n",
    "        countries = cluster_df[cluster_df['Cluster'] == cluster_id]['Country'].tolist()\n",
    "        print(f\"Cluster {cluster_id}: {', '.join(countries)}\")\n",
    "    \n",
    "    # Save clustering results\n",
    "    cluster_df.to_csv(os.path.join(RESULTS_DIR, 'multimodal_clusters.csv'), index=False)\n",
    "    \n",
    "    # 10. Canonical Correlation Analysis could be added here\n",
    "    \n",
    "    # 11. Analysis of specific patterns\n",
    "    # For example, find countries with similar text but different audio, or vice versa\n",
    "    \n",
    "    # Calculate average similarity for each country in each modality\n",
    "    text_avg_sim = np.mean(text_sim, axis=1)\n",
    "    audio_avg_sim = np.mean(audio_sim, axis=1)\n",
    "    \n",
    "    # Find countries with high difference between text and audio similarity\n",
    "    sim_diff = np.abs(text_avg_sim - audio_avg_sim)\n",
    "    \n",
    "    # Top 5 countries with highest difference\n",
    "    top_diff_indices = np.argsort(sim_diff)[::-1][:5]\n",
    "    \n",
    "    print(\"\\nCountries with highest difference between text and audio similarity:\")\n",
    "    for idx in top_diff_indices:\n",
    "        country = common_countries[idx]\n",
    "        print(f\"{country}: Text sim={text_avg_sim[idx]:.4f}, Audio sim={audio_avg_sim[idx]:.4f}, Diff={sim_diff[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
