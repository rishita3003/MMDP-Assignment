{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3 Part d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " # Part D: Audio Analysis\n",
    "    audio_features = load_anthem_audio()\n",
    "    audio_df = analyze_anthem_audio(audio_features)\n",
    "    \n",
    "    # Part E: Multimodal Analysis\n",
    "    analyze_multimodal_correlations(processed_texts, audio_df, tfidf_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ANTHEM_AUDIO_DIR = \"anthem_audio\"     # Folder containing anthem audio files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# PART D: AUDIO ANALYSIS\n",
    "#################################################################\n",
    "\n",
    "def load_anthem_audio():\n",
    "    \"\"\"Load audio features for all anthem audio files.\"\"\"\n",
    "    audio_features = {}\n",
    "    \n",
    "    for file_path in glob.glob(os.path.join(ANTHEM_AUDIO_DIR, \"*.mp3\")):\n",
    "        try:\n",
    "            country_name = os.path.basename(file_path).replace('.mp3', '')\n",
    "            \n",
    "            # Load audio file\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            \n",
    "            # Extract features\n",
    "            # Tempo and beat information\n",
    "            tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "            \n",
    "            # Spectral features\n",
    "            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "            \n",
    "            # MFCCs\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            \n",
    "            # Chroma features\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            \n",
    "            # Extract summary statistics for each feature\n",
    "            features = {\n",
    "                'tempo': tempo,\n",
    "                'spectral_centroid_mean': np.mean(spectral_centroids),\n",
    "                'spectral_centroid_std': np.std(spectral_centroids),\n",
    "                'spectral_rolloff_mean': np.mean(spectral_rolloff),\n",
    "                'spectral_rolloff_std': np.std(spectral_rolloff),\n",
    "            }\n",
    "            \n",
    "            # Add MFCC statistics\n",
    "            for i in range(13):\n",
    "                features[f'mfcc{i+1}_mean'] = np.mean(mfccs[i])\n",
    "                features[f'mfcc{i+1}_std'] = np.std(mfccs[i])\n",
    "            \n",
    "            # Add chroma statistics\n",
    "            chroma_means = np.mean(chroma, axis=1)\n",
    "            for i in range(12):\n",
    "                features[f'chroma{i+1}'] = chroma_means[i]\n",
    "            \n",
    "            audio_features[country_name] = features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded audio features for {len(audio_features)} anthems.\")\n",
    "    return audio_features\n",
    "\n",
    "def analyze_anthem_audio(audio_features):\n",
    "    \"\"\"Perform analysis on audio features.\"\"\"\n",
    "    print(\"\\n--- AUDIO ANALYSIS ---\")\n",
    "    \n",
    "    if not audio_features:\n",
    "        print(\"No audio features available for analysis.\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    audio_df = pd.DataFrame.from_dict(audio_features, orient='index')\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nAudio feature statistics:\")\n",
    "    print(f\"Average tempo: {audio_df['tempo'].mean():.2f} BPM\")\n",
    "    print(f\"Tempo range: {audio_df['tempo'].min():.2f} - {audio_df['tempo'].max():.2f} BPM\")\n",
    "    \n",
    "    # Find fastest and slowest anthems\n",
    "    fastest = audio_df['tempo'].idxmax()\n",
    "    slowest = audio_df['tempo'].idxmin()\n",
    "    print(f\"Fastest anthem: {fastest} ({audio_df.loc[fastest, 'tempo']:.2f} BPM)\")\n",
    "    print(f\"Slowest anthem: {slowest} ({audio_df.loc[slowest, 'tempo']:.2f} BPM)\")\n",
    "    \n",
    "    # Save audio features\n",
    "    audio_df.to_csv(os.path.join(RESULTS_DIR, 'anthem_audio_features.csv'))\n",
    "    \n",
    "    # Correlation heatmap of audio features\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation = audio_df.corr()\n",
    "    sns.heatmap(correlation, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Correlation Between Audio Features')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'audio_correlation.png'))\n",
    "    \n",
    "    # PCA on audio features\n",
    "    # Normalize features first\n",
    "    audio_df_norm = (audio_df - audio_df.mean()) / audio_df.std()\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(audio_df_norm.fillna(0))  # Handle any NaN values\n",
    "    \n",
    "    # Create PCA plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\n",
    "    \n",
    "    # Add country labels\n",
    "    for i, country in enumerate(audio_df.index):\n",
    "        plt.annotate(country, (pca_result[i, 0], pca_result[i, 1]), \n",
    "                    fontsize=8, alpha=0.8)\n",
    "    \n",
    "    plt.title('PCA of National Anthem Audio Features')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'anthem_audio_pca.png'))\n",
    "    \n",
    "    # Clustering analysis\n",
    "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "    clusters = kmeans.fit_predict(audio_df_norm.fillna(0))\n",
    "    \n",
    "    # Create a DataFrame with clustering results\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'Country': audio_df.index,\n",
    "        'Cluster': clusters\n",
    "    })\n",
    "    \n",
    "    # Print clusters\n",
    "    print(\"\\nAnthem audio clusters:\")\n",
    "    for cluster_id in range(5):\n",
    "        countries = cluster_df[cluster_df['Cluster'] == cluster_id]['Country'].tolist()\n",
    "        print(f\"Cluster {cluster_id}: {', '.join(countries[:5])}{'...' if len(countries) > 5 else ''}\")\n",
    "    \n",
    "    # Save clustering results\n",
    "    cluster_df.to_csv(os.path.join(RESULTS_DIR, 'anthem_audio_clusters.csv'), index=False)\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nMost influential audio features for each principal component:\")\n",
    "    feature_names = audio_df.columns\n",
    "    for i, component in enumerate(pca.components_):\n",
    "        sorted_idx = np.argsort(np.abs(component))[::-1]\n",
    "        top_features = [(feature_names[idx], component[idx]) for idx in sorted_idx[:5]]\n",
    "        print(f\"PC{i+1}: {top_features}\")\n",
    "    \n",
    "    return audio_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
